<!DOCTYPE html>
<!--[if IEMobile 7]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html
  class="no-js"
  lang="en"
><!--<![endif]-->
  <head>
    <meta charset="utf-8" />
    <title>Using schemas to speed up reading into Spark DataFrames</title>
    <meta name="author" content="Jodie Burchell" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="description" content="Using schemas to speed up reading into Spark DataFrames written August 24, 2020 in pyspark">
  <meta name="keywords" content="python, data science, aws, sagemaker, s3, pyspark" />

    <link
      rel="canonical"
      href="/blog/2020/08/using-schemas-to-speed-up-reading-into-spark-dataframes.html"
    />

    <link href="/favicon.png" rel="icon" />

      <link
      href="/theme/css/screen.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="/theme/css/tomorrow.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
     <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.js"></script>
    <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
    <!-- KaTeX for math rendering -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css"
      integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD"
      crossorigin="anonymous"
    />
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js"
      integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js"
      integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc"
      crossorigin="anonymous"
    ></script>
   </head>
  <body>
    <a href="/" class="home-icon">
      <img src="/theme/images/home.png" />
    </a>
<article role="article" class="full-single-article">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h1>Using schemas to speed up reading into Spark DataFrames</h1>
        <div class="meta">
          written <time datetime="2020-08-24T00:00:00+02:00">August 24, 2020</time>
          in <span class="categories">
            <a href="/tag/pyspark.html">pyspark</a>          </span>
        </div>
        <p>While Spark is the best thing since sliced bread for dealing with big data, I definitely realise I have a lot to learn before I can use it to its full potential. One trick I recently discovered was using explicit schemas to speed up how fast Spark can read a <span class="caps">CSV</span> into a&nbsp;DataFrame.</p>
<p>When using <code>spark.read_csv</code> to read in a <span class="caps">CSV</span>, the most straightforward way is to set the <code>inferSchema</code> argument to <code>True</code>. This means that Spark will attempt to check the data in order to work out what type of data each column&nbsp;is. </p>
<p>The problem with this operation is that it&#8217;s quite memory intensive, especially for large datasets, as Spark needs to look at a sufficient amount of data in order to correctly infer the type. Imagine that you have a column with integers in the first 1000 rows, but then a string in the 1001th row. If Spark had inferred this column was an <code>IntegerType</code> based on the top few rows, then we would end up with missing values for each of the rows containing a string. As such, Spark either needs to scan the whole dataset, or randomly sample enough rows to infer the&nbsp;type.</p>
<p>One way we can get around this is by determining the type of the data beforehand and passing this information to Spark using an schema. The syntax for this is pretty straightforward. Each column&#8217;s name and type is defined using the <code>StructField</code> method from <code>pyspark.sql</code>:</p>
<div class="highlight"><pre><span></span><span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;trip_id&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>


<p>The three arguments that <code>StructField</code> takes are the name you&#8217;d like to give the column, the column&#8217;s data type, and whether the field can contain null values (as a boolean). The available column data types are also in <code>pyspark.sql</code>, and cover a wide type of possible data types, from string, float and integer to boolean and datetime. A <code>StructField</code> is created for each column, and these are passed as a list to <code>pyspark.sql</code><span class="quo">&#8216;</span>s <code>StructType</code>. This schema can then be passed to <code>spark.read.csv</code><span class="quo">&#8216;</span>s <code>schema</code> argument.</p>
<div class="highlight"><pre><span></span><span class="n">StructType</span><span class="p">(</span>
    <span class="p">[</span><span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;trip_id&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;call_type&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)]</span>
<span class="p">)</span>
</pre></div>


<p>In order to test how much faster it is to use a schema, I will be using the <a href="https://archive.ics.uci.edu/ml/datasets/Taxi+Service+Trajectory+-+Prediction+Challenge,+ECML+PKDD+2015">Taxi Service Trajectory</a> dataset from the <span class="caps">UCI</span> Machine Learning Repository. This dataset has 9 columns and around 1.7 million&nbsp;rows.</p>
<p>We&#8217;ll first set up our <code>SparkSession</code> to be able to access our data on&nbsp;S3:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark</span> <span class="kn">import</span> <span class="n">SparkConf</span>
<span class="kn">from</span> <span class="nn">pyspark.sql</span> <span class="kn">import</span> <span class="n">SparkSession</span>
<span class="kn">import</span> <span class="nn">sagemaker_pyspark</span>
<span class="kn">import</span> <span class="nn">botocore.session</span>

<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">time</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.types</span> <span class="kn">import</span> <span class="n">StructType</span><span class="p">,</span> <span class="n">StructField</span><span class="p">,</span> <span class="n">StringType</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">,</span> <span class="n">LongType</span><span class="p">,</span> <span class="n">BooleanType</span>

<span class="n">session</span> <span class="o">=</span> <span class="n">botocore</span><span class="o">.</span><span class="n">session</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
<span class="n">credentials</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_credentials</span><span class="p">()</span>

<span class="n">conf</span> <span class="o">=</span> <span class="p">(</span><span class="n">SparkConf</span><span class="p">()</span>
        <span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.driver.extraClassPath&quot;</span><span class="p">,</span> <span class="s2">&quot;:&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sagemaker_pyspark</span><span class="o">.</span><span class="n">classpath_jars</span><span class="p">())))</span>

<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span>
    <span class="o">.</span><span class="n">builder</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="n">conf</span><span class="o">=</span><span class="n">conf</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s1">&#39;fs.s3a.access.key&#39;</span><span class="p">,</span> <span class="n">credentials</span><span class="o">.</span><span class="n">access_key</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s1">&#39;fs.s3a.secret.key&#39;</span><span class="p">,</span> <span class="n">credentials</span><span class="o">.</span><span class="n">secret_key</span><span class="p">)</span>
    <span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;schema_test&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>We&#8217;ll also set up our data&nbsp;path:</p>
<div class="highlight"><pre><span></span><span class="n">bucket</span> <span class="o">=</span> <span class="s2">&quot;sagemaker-pyspark&quot;</span>
<span class="n">data_key</span> <span class="o">=</span> <span class="s2">&quot;train.csv&quot;</span>
<span class="n">data_location</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;s3a://</span><span class="si">{bucket}</span><span class="s2">/</span><span class="si">{data_key}</span><span class="s2">&quot;</span>
</pre></div>


<p>Let&#8217;s first time how long it takes to read in these data when Spark has to infer the&nbsp;schema:</p>
<div class="highlight"><pre><span></span><span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">data_inferred</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">data_location</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;True&#39;</span><span class="p">,</span> <span class="n">inferSchema</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Completed in </span><span class="si">%s</span><span class="s1"> sec.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Completed in 28.1013503074646 sec.</span>
</pre></div>


<p>We&#8217;ll now compare how long it takes when we explicitly tell Spark what the data schema&nbsp;is:</p>
<div class="highlight"><pre><span></span><span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>

<span class="n">schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span>
    <span class="p">[</span><span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;trip_id&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;call_type&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;origin_call&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;origin_stand&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;taxi_id&quot;</span><span class="p">,</span> <span class="n">LongType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;timestamp&quot;</span><span class="p">,</span> <span class="n">LongType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;day_type&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;missing_data&quot;</span><span class="p">,</span> <span class="n">BooleanType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
    <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;polyline&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)]</span>
<span class="p">)</span>
<span class="n">data_schema</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="n">data_location</span><span class="p">,</span> <span class="n">header</span> <span class="o">=</span> <span class="s1">&#39;False&#39;</span><span class="p">,</span> <span class="n">schema</span> <span class="o">=</span> <span class="n">schema</span><span class="p">)</span>

<span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Completed in </span><span class="si">%s</span><span class="s1"> sec.&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span></span><span class="err">Completed in 2.506075620651245 sec.</span>
</pre></div>


<p>The data are read in around 10 times faster when we give Spark the schema rather than asking it to infer it! Obviously this is a more practical step when you have data with fewer variables, but when reading truly large data, it is an easy way to save some processing&nbsp;time.</p>
        <hr class="divider-short"/>
        <!-- Disqus goes here -->
        <!-- <section>
          <h1>Comments</h1>
          <div id="disqus_thread" aria-live="polite">Disqus goes here</div>
        </section>
        -->
      </div>
    </div>
  </div>
</article>
    <footer id="footer" class="her-row">
      <div class="container">
        <div class="row">
          <div class="col-md-1">
            <a href="/"><h4>Home</h4></a>
          </div>

          <div class="col-md-2">
            <div class="social-icon-list">
              <a href="https://twitter.com/t_redactyl"
                ><img
                  src="/theme/images/glyphicons_social_31_twitter.png"
              /></a>
               <a href="https://github.com/t-redactyl"
                ><img
                  src="/theme/images/glyphicons_social_21_github.png"
              /></a>
              </div>
          </div>
          <div class="pull-right">
            <h4>
              Powered by <a href="http://blog.getpelican.com/">Pelican</a>.
              Designed by <a href="http://AdrianArtiles.com">Adrian Artiles</a>.
              Title picture by
              <a
                href="https://pixabay.com/en/brandenburg-gate-berlin-landmark-2010656/"
                >Couleur via Pixabay</a
              >.
            </h4>
          </div>
        </div>
      </div>
    </footer>

    <!-- KaTeX rendering -->
    <script>
      renderMathInElement(document.body);
    </script>

   </body>
</html>