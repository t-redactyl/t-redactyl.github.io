<!DOCTYPE html>
<!--[if IEMobile 7]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html
  class="no-js"
  lang="en"
><!--<![endif]-->
  <head>
    <meta charset="utf-8" />
    <title>How do convolutional neural networks work?</title>
    <meta name="author" content="Jodie Burchell" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="description" content="How do convolutional neural networks work? written July 27, 2024 in llms,machine learning">
  <meta name="keywords" content="psychology, intelligence, agi, artificial general intelligence,, artificial superintelligence, llms, large languages models, gpt-1, gpt-2, gpt-3.5, gpt-4o, language" />

    <link
      rel="canonical"
      href="/blog/2024/07/how-do-convolutional-neural-networks-work.html"
    />

    <link href="/favicon.png" rel="icon" />

      <link
      href="/theme/css/screen.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="/theme/css/tomorrow.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
     <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.js"></script>
    <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
    <!-- KaTeX for math rendering -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css"
      integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD"
      crossorigin="anonymous"
    />
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js"
      integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js"
      integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc"
      crossorigin="anonymous"
    ></script>
   </head>
  <body>
    <a href="/" class="home-icon">
      <img src="/theme/images/home.png" />
    </a>
<article role="article" class="full-single-article">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h1>How do convolutional neural networks work?</h1>
        <div class="meta">
          written <time datetime="2024-07-27T00:00:00+02:00">July 27, 2024</time>
          in <span class="categories">
            <a href="/tag/llms.html">llms</a>,            <a href="/tag/machine-learning.html">machine learning</a>          </span>
        </div>
        <p>Convolutional neural networks, CNNs, convnets, call them what you like - these powerful neural nets remain one of the most popular type of models for classifying images. But have you ever wondered how they work? In this blog post, we&#8217;ll go through how these models&nbsp;work.</p>
<p>For this blog post, I relied heavily on François Chollet&#8217;s wonderful introduction to deep learning, <a href="https://www.manning.com/books/deep-learning-with-python-second-edition">Deep Learning with Python</a>. If you want one book to gently introduce you to neural networks, this would be the one I recommend. I also used <a href="https://courses.cs.washington.edu/courses/cse416/22su/lectures/10/lecture_10.pdf">these lecture notes</a> from the University of Washington&#8217;s <a href="https://courses.cs.washington.edu/courses/cse416/">Introduction to Machine Learning course</a>.</p>
<h2>How do CNNs process&nbsp;images?</h2>
<p>CNNs take in raw images as inputs, and divide each of them into their respective pixels. Below you can see a <a href="https://www.planetminecraft.com/blog/pixel-art-3---lock/">greyscale 16 x 16 pixel image</a>, which has been divided into its 256 respective&nbsp;pixels.</p>
<p>Within each pixel, there is information about the intensity of the image at that point. For greyscale images, we only have information about the intensity of the greyscale. This means that for greyscale images, we only have one <em>channel</em>, as you can see&nbsp;below.</p>
<p><img src="/figure/cnn-greyscale-input.png" title="" style="display: block; margin: auto;" /></p>
<p>However, for colour images, we have information about the intensity of red, green and blue in each pixel, so we have a channel with information about the intensity of red in the image, another with the intensity of green, and a final one with the intensity of blue, giving colour images three channels in total. You can see this in a <a href="https://photonstorm.com/art/tutorials-art/16x16-pixel-art-tutorial">colour 16 x 16 pixel image</a>&nbsp;below.</p>
<p><img src="/figure/cnn-colour-input.png" title="" style="display: block; margin: auto;" /></p>
<p>Each pixel is treated as a feature in the image, with the total number of input features being calculated by the image <span class="math">\(\textrm{height} \times \textrm{width} \times \textrm{number of channels}\)</span>. So for our <span class="math">\(16 \times 16\)</span> grey scale image above, the total number of input features would be <span class="math">\(16 \times 16 \times 1 = 256\)</span>. For the <span class="math">\(16 \times 16\)</span> colour image, this would be <span class="math">\(16 \times 16 \times 3 = 768\)</span>. You can see that using colour images is a lot more computationally expensive than greyscale&nbsp;ones!</p>
<p>So for greyscale images, we now have one matrix of size <span class="math">\(\textrm{height} \times \textrm{width}\)</span>, and for colour images, we have three such matrices. How do we now convert these into a model input? Well, the whole matrix is unrolled so that it is converted into a vector (a 1D array). Let&#8217;s have a look at how this might work in&nbsp;NumPy.</p>
<p>For our greyscale image, we have a <span class="math">\(16 \times 16\)</span> matrix containing all of the greyscale intensity&nbsp;values:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span> 
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">174</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">174</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span>  <span class="mi">53</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">174</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span>  <span class="mi">65</span><span class="p">,</span> <span class="mi">174</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">146</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">167</span><span class="p">,</span> <span class="mi">153</span><span class="p">,</span> <span class="mi">138</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span>  <span class="mi">95</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">109</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                  <span class="p">[</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">],</span>
                 <span class="p">])</span>
<span class="n">image</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">(16, 16)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">image</span><span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="p">:]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,</span>
<span class="err">       255, 255, 255])</span>
</code></pre></div>

<p>To feed this into a <span class="caps">CNN</span>, we need to unroll&nbsp;it:</p>
<div class="highlight"><pre><span></span><code><span class="n">image_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
<span class="n">image_input</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">(256,)</span>
</code></pre></div>

<p>We can see we now have an input vector with 256&nbsp;features.</p>
<h2>The convolutional&nbsp;layer</h2>
<p>Now that we understand how CNNs treat images as inputs, let&#8217;s have a look at the first type of hidden layer in these networks: the convolutional&nbsp;layer.</p>
<p>The goal of the convolutional layer is to try to summarise the input, called a <em>feature map</em>, by extracting meaningful visual features. Let&#8217;s see how this might work with our image&nbsp;input.</p>
<p>Firstly, a window, normally of sizes <span class="math">\(3 \times 3\)</span>, <span class="math">\(5 \times 5\)</span> or <span class="math">\(7 \times 7\)</span> is slid across the image. At each point that the window stops, the part of the image under it, called a <em>patch</em>, is extracted as a matrix. The sum of element-wise products is then taken between this matrix, and another matrix of the same size called a <em>convolutional kernel</em>. The values in each convolutional kernel are learned gradually over the course of model training (as with any weights in a neural network), and models that have successfully learned from their inputs will have kernels that capture some sort of key information within an image. This information could include dominant outlines, structural patterns, and even specific&nbsp;objects.</p>
<p>There are <a href="https://courses.cs.washington.edu/courses/cse416/22su/lectures/10/lecture_10.pdf">specific kernels that do certain transformations to the image</a>. For example, this matrix sharpens&nbsp;images:</p>
<div class="math">$$\begin{bmatrix} 0 &amp; -1 &amp; 0 \\
                  -1 &amp; 5 &amp; -1 \\
                  0 &amp; -1 &amp; 0 \\
  \end{bmatrix}
$$</div>
<p>and this one detects&nbsp;edges:</p>
<div class="math">$$\begin{bmatrix} -1 &amp; -1 &amp; -1 \\
                  -1 &amp; 8 &amp; -1 \\
                  -1 &amp; -1 &amp; -1 \\
  \end{bmatrix}
$$</div>
<p>As the sum of element-wise products is taken between the patch and the convolutional kernel, we end up with a single number. This number is then assigned to the output matrix from the convolutional layer. We repeat this operation with every patch in the input, until we&#8217;ve covered the whole feature map, ending up with a single <em>filter</em> of the feature&nbsp;map. </p>
<p><img src="/figure/cnn-filter-calculation.gif" title="" style="display: block; margin: auto;" /></p>
<p>This filter will be of size <span class="math">\(\textrm{feature map height} - 2 \times \textrm{feature map width} - 2\)</span> in the case of a <span class="math">\(3 \times 3\)</span> window, so in the case of our <span class="math">\(16 \times 16\)</span> image, the resulting filter would be <span class="math">\(14 \times 14\)</span>. This is because with a <span class="math">\(3 \times 3\)</span> window, the window can only fit in the image 14 times along the x-axis and 14 times along the y-axis, and each window is reduced to a single value in the feature. With a <span class="math">\(5 \times 5\)</span> window, the resulting filter will be <span class="math">\(\textrm{feature map height} - 4 \times \textrm{feature map width} - 4\)</span>, and finally, with a <span class="math">\(7 \times 7\)</span> window, the resulting filter will be <span class="math">\(\textrm{feature map height} - 6 \times \textrm{feature map width} - 6\)</span>.</p>
<p>Let&#8217;s see how these filters are created by doing this step-by-step in&nbsp;NumPy.</p>
<p>Firstly, let&#8217;s create the window using the <code>view_as_windows</code> function from <code>scikit-image</code>. We&#8217;ll work with a <span class="math">\(3 \times 3\)</span>&nbsp;window.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">skimage.util.shape</span> <span class="kn">import</span> <span class="n">view_as_windows</span>

<span class="n">window_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</code></pre></div>

<p>We apply this to our greyscale image from earlier in the post. We can see we now have an array containing all of our <span class="math">\(3 \times 3\)</span> patches, which are two dimensional NumPy arrays. As the window fits 14 times along the x-axis and 14 times along the y-axis, we have 196 of these patches in&nbsp;total. </p>
<div class="highlight"><pre><span></span><code><span class="n">patches</span> <span class="o">=</span> <span class="n">view_as_windows</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">window_shape</span><span class="p">)</span>
<span class="n">patches</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">(14, 14, 3, 3)</span>
</code></pre></div>

<p>Let&#8217;s see the first of these&nbsp;patches:</p>
<div class="highlight"><pre><span></span><code><span class="n">patches</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([[255, 255, 255],</span>
<span class="err">       [255, 255, 255],</span>
<span class="err">       [255, 255, 255]])</span>
</code></pre></div>

<p>We can see this is the upper-left corner of our image, where all pixels have an intensity of 255 (i.e.,&nbsp;white).</p>
<p>Let&#8217;s now create our convolutional kernel. As I explained earlier, the specific values will be determined by the model, but we can for now use the kernel that sharpens&nbsp;images.</p>
<div class="highlight"><pre><span></span><code><span class="n">convolutional_kernel</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
                        <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
</code></pre></div>

<p>We now need to take the element-wise product between each of the values in the patch and the values in the convolutional kernel. We can do this by multiplying the corresponding elements in the two matrices together, then summing the values. We need to sum twice, as the first sum operation sums along each column in the&nbsp;matrix.</p>
<div class="highlight"><pre><span></span><code><span class="nb">sum</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">patches</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">convolutional_kernel</span><span class="p">))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">255</span>
</code></pre></div>

<p>The value is, unsurprisingly, 255. Let&#8217;s now repeat this operation for every patch from the image. This is equivalent to sliding the window along the top row of the image matrix, calculating the sum of element-wise products each time it stops, then repeating this for the second row, and so on until the 14th&nbsp;row. </p>
<p>We&#8217;ll assign each sum of products to a filter matrix, which we&#8217;ll initialise by creating a <span class="math">\(14 \times 14\)</span> matrix made up of&nbsp;zeros.</p>
<div class="highlight"><pre><span></span><code><span class="n">filter_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">14</span><span class="p">,</span> <span class="mi">14</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">14</span><span class="p">):</span>
        <span class="n">filter_value</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">patches</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*</span> <span class="n">convolutional_kernel</span><span class="p">))</span>
        <span class="n">filter_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">filter_value</span>
</code></pre></div>

<p>We can see that the resulting matrix looks quite similar to the input matrix, but smaller and with some numbers transformed. You can also see we&#8217;ve departed from the 0 to 255 greyscale&nbsp;values.</p>
<div class="highlight"><pre><span></span><code><span class="n">filter_matrix</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([[ 255.,  255.,  255.,  255.,  255.,  255.,  394.,  394.,  401.,</span>
<span class="err">         255.,  255.,  255.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  255.,  255.,  533., -192.,  -53., -190.,</span>
<span class="err">         401.,  255.,  255.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  255.,  533., -214.,   90.,  139., -227.,</span>
<span class="err">         503.,  401.,  255.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  394., -184.,   50.,  481.,  357.,  503.,</span>
<span class="err">           0., -234.,  401.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  394.,  -60.,  110.,  438.,  357.,  473.,</span>
<span class="err">          90.,  -25.,  394.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  533., -104.,  113.,  118.,  125.,   53.,</span>
<span class="err">          47., -150.,  575.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  394., -213.,  276.,  192.,  512., -232.,  343.,</span>
<span class="err">         167.,  201., -289.,  415.,  255.],</span>
<span class="err">       [ 255.,  255.,  394.,  -60.,  162.,  276., -267.,    5., -235.,</span>
<span class="err">         249.,  188.,  -18.,  394.,  255.],</span>
<span class="err">       [ 255.,  255.,  394.,  -39.,  176.,  174.,  406., -165.,  519.,</span>
<span class="err">         147.,  267., -172.,  415.,  255.],</span>
<span class="err">       [ 255.,  255.,  415., -144.,  204.,  195.,  262., -248.,  273.,</span>
<span class="err">         188.,  184.,  -67.,  401.,  255.],</span>
<span class="err">       [ 255.,  255.,  415., -276.,  213.,  190.,  239.,  320.,  232.,</span>
<span class="err">         177.,  159., -212.,  401.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  554., -171., -158.,  -88.,  -60., -109.,</span>
<span class="err">         -53., -184.,  540.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  255.,  394.,  415.,  401.,  394.,  401.,</span>
<span class="err">         394.,  394.,  255.,  255.,  255.],</span>
<span class="err">       [ 255.,  255.,  255.,  255.,  255.,  255.,  255.,  255.,  255.,</span>
<span class="err">         255.,  255.,  255.,  255.,  255.]])</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">filter_matrix</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([255., 255., 255., 255., 394., 415., 401., 394., 401., 394., 394.,</span>
<span class="err">       255., 255., 255.])</span>
</code></pre></div>

<p>We can see how the filter has transformed the image by visualising it below using <code>matplotlib</code>. As we&#8217;re not dealing with greyscale values anymore, this is not strictly how the image &#8220;looks&#8221; to the network, but it gives us an&nbsp;approximation.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">filter_matrix</span><span class="p">,</span> 
           <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> 
           <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">();</span>
</code></pre></div>

<p><img src="/figure/cnn-filter-example.png" title="" style="display: block; margin: auto;" /></p>
<p>If you want the filter matrix to be the same size as the input matrix, you can apply padding. This is where extra rows, with a value of zero, are added to the outside of the feature map. The number of rows added will be total to the number of rows &#8220;lost&#8221; when calculating the values in the filter, so in the case of a <span class="math">\(3 \times 3\)</span> window, two rows would added. You can see this in the diagram&nbsp;below:</p>
<p><img src="/figure/cnn-padding-example.png" title="" style="display: block; margin: auto;" /></p>
<p>Now, we&#8217;ve only discussed making <em>one</em> filter from our input image. However, one of the hyperparameters you can set in the convolutional layer is the number of filters you want the model to extract. This means, just like the input layer, the output from the convolutional layer also has three dimensions: <em>height</em> and <em>width</em>, which as we discussed above refers to the dimensions of each of the filters, and <em>number of channels</em>, which now refers to the number of filters you want made over the feature&nbsp;map.</p>
<p>The final thing to cover about the convolutional layer is a parameter called <em>stride</em>. So far, when we moved the window over the feature map, we were just moving it one pixel at a time. However, it is possible to change the stride so that you move 2 or more pixels at a time. This makes the output matrix less large, but is rarely used in practice. Instead, we rely on the next type of layer in CNNs, pooling layers, to reduce the size of the feature map as it moves through the&nbsp;network.</p>
<h2>The pooling&nbsp;layer</h2>
<p>Usually following the convolutional layer, there is another type of layer called a <em>pooling layer</em>. Pooling is designed to aggressively downsample the feature map by again sliding windows over each filter, and taking some aggregation of the values inside the window. There are several operations that can be used, but the most common of these is taking the maximum. Max pooling usually uses a <span class="math">\(14 \times 14\)</span> window and a stride of 2, so that we get non-overlapping patches that we can conduct the pooling operation over. We can see how max pooling works&nbsp;below.</p>
<p>Let&#8217;s say that for our <span class="math">\(14 \times 14\)</span> feature map, the result of multiplying our input matrix by the sharpening convolutional matrix, we apply a max pooling operation. We can see how this would work in this&nbsp;diagram:</p>
<p><img src="/figure/cnn-max-pooling.png" title="" style="display: block; margin: auto;" /></p>
<p>We can apply see how this works step-by-step by applying it to our filter matrix that we calculated&nbsp;above.</p>
<p>Again, we define our window, this time a <span class="math">\(2 \times 2\)</span> window, and break the feature map into patches. We use the <code>step</code> argument to define a stride of&nbsp;2.</p>
<div class="highlight"><pre><span></span><code><span class="n">window_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">patches</span> <span class="o">=</span> <span class="n">view_as_windows</span><span class="p">(</span><span class="n">filter_matrix</span><span class="p">,</span> <span class="n">window_shape</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">patches</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">(7, 7, 2, 2)</span>
</code></pre></div>

<p>You can see that, as in the diagram above, we can fit 7 windows along the x-axis and 7 along the y-axis, leaving us with 49 <span class="math">\(2 \times 2\)</span>&nbsp;patches.</p>
<p>Again, let&#8217;s have a look at the first&nbsp;patch:</p>
<div class="highlight"><pre><span></span><code><span class="n">patches</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([[255., 255.],</span>
<span class="err">       [255., 255.]])</span>
</code></pre></div>

<p>We can get the maximum value for each patch by calling the <code>max()</code> function over the&nbsp;array.</p>
<div class="highlight"><pre><span></span><code><span class="n">patches</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">255.0</span>
</code></pre></div>

<p>Now, all we need to do to take the max of each patch. We&#8217;ll again use a nested for loop to do&nbsp;this:</p>
<div class="highlight"><pre><span></span><code><span class="n">max_pooling_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">7</span><span class="p">):</span>
        <span class="n">max_value</span> <span class="o">=</span> <span class="n">patches</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
        <span class="n">max_pooling_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_value</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="n">max_pooling_matrix</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([[255., 255., 533., 394., 401., 255., 255.],</span>
<span class="err">       [255., 394., 533., 481., 503., 401., 255.],</span>
<span class="err">       [255., 533., 113., 438., 473., 575., 255.],</span>
<span class="err">       [255., 394., 276., 512., 343., 201., 415.],</span>
<span class="err">       [255., 415., 204., 406., 519., 267., 415.],</span>
<span class="err">       [255., 554., 213., 320., 232., 540., 401.],</span>
<span class="err">       [255., 255., 415., 401., 401., 394., 255.]])</span>
</code></pre></div>

<p>And with that, we&#8217;ve understood the two types of layers that make up CNNs! These layers will be repeated, with a convolutional layer followed by a pooling layer, until the network gets to the final prediction layer (which we&#8217;ll cover in&nbsp;second).</p>
<p>How many of these layers that you include is, again, a subjective decision and will be based on how big and complex your image is. For example, in Chollet&#8217;s chapter on CNNs, he shows two examples. For the <a href="https://www.kaggle.com/datasets/hojjatk/mnist-dataset"><span class="caps">MNIST</span> digit classication dataset</a>, which has <span class="math">\(26 \times 26\)</span> pixel images, he uses three convolutional layers and three max pooling layers. For the larger and more complex images in the <a href="https://www.kaggle.com/c/dogs-vs-cats">Dogs vs Cats dataset</a>, he uses four of each&nbsp;layer.</p>
<p>So, the final question you might ask about these two layers is: why bother with these complex layer types? Why not just use dense layers to learn the features from the&nbsp;images?</p>
<p>There are a few reasons for this. The convolutional layers do the following:
* <strong>They learn translation invariant patterns</strong>: This means that the network is able to learn patterns that make up meaningful features, no matter where they occur in the image. This is because the convolutional layers force the network to only focus on small parts of the image at a time, which means that if the network learns, for example, diagonal lines in one part of time image, it can recognise them anywhere. If we used a dense layer, the network would need to learn the same feature all over again if it was used in a different part of the image in a different image. This mimics the way our own visual system recognises visual features, meaning the network can learn a lot more about images with fewer training examples.
* <strong>They are capable of learning hierarchies of visual features</strong>: Convolutional layers first learn simple features, such as the orientation of lines. As the features are passed through more convolutional layers, these features will be aggregated more and more, first into shapes, then features, as you can see below. This actually also mimics how visual inputs are processed in our visual&nbsp;system.</p>
<p><img src="/figure/cnn-feature-hierarchy.png" title="" style="display: block; margin: auto;" /></p>
<p><a href="https://www.flaticon.com/free-icon/triceratops_472861">Image&nbsp;credit</a></p>
<p>The pooling layers also play an important role in how the network learns. Without pooling, the windows would remain relatively small as they progressed through the network. Our <span class="math">\(3 \times 3\)</span> window would analyse a <span class="math">\(5 \times 5\)</span> area in the second layer, and a <span class="math">\(7 \times 7\)</span> area in the third layer &#8230; as you can see, even with our small <span class="math">\(16 \times 16\)</span> image, we&#8217;re not even close to the network being able to analyse the whole image. Pooling halves the feature space each time, allowing the convolutional layers to more efficiently see larger and larger parts of the image as the network progresses and allow it to build up that nice hierarchy of&nbsp;features.</p>
<p>Additionally, as we have multiple channels per convolutional layer, without downsampling the number of features in the feature map, we&#8217;d potentially end up an absolutely enormous number of coefficients by the time we hit the dense layers we need for classification. As well as being computationally inefficient, it would also lead to model&nbsp;overfitting. </p>
<h2>The dense&nbsp;layers</h2>
<p>Finally, we of course need to get the <span class="caps">CNN</span> to solve a classification problem, not just recognise image features! This is where the final layers come&nbsp;in. </p>
<p>After the final pooling layer, we&#8217;re left with a three dimensional array, with the dimensions height, width and number of channels. In order to connect this to a dense layer, we first need to flatten this array into a 1-dimensional&nbsp;array.</p>
<div class="highlight"><pre><span></span><code>
</code></pre></div>
        <hr class="divider-short"/>
        <!-- Disqus goes here -->
        <!-- <section>
          <h1>Comments</h1>
          <div id="disqus_thread" aria-live="polite">Disqus goes here</div>
        </section>
        -->
      </div>
    </div>
  </div>
</article>
    <footer id="footer" class="her-row">
      <div class="container">
        <div class="row">
          <div class="col-md-1">
            <a href="/"><h4>Home</h4></a>
          </div>

          <div class="col-md-2">
            <div class="social-icon-list">
              <a href="https://twitter.com/t_redactyl"
                ><img
                  src="/theme/images/glyphicons_social_31_twitter.png"
              /></a>
               <a href="https://github.com/t-redactyl"
                ><img
                  src="/theme/images/glyphicons_social_21_github.png"
              /></a>
              </div>
          </div>
          <div class="pull-right">
            <h4>
              Powered by <a href="http://blog.getpelican.com/">Pelican</a>.
              Designed by <a href="http://AdrianArtiles.com">Adrian Artiles</a>.
              Title picture by
              <a
                href="https://pixabay.com/en/brandenburg-gate-berlin-landmark-2010656/"
                >Couleur via Pixabay</a
              >.
            </h4>
          </div>
        </div>
      </div>
    </footer>

    <!-- KaTeX rendering -->
    <script>
      renderMathInElement(document.body);
    </script>

   </body>
</html>