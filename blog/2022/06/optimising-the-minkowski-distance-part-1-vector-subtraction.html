<!DOCTYPE html>
<!--[if IEMobile 7]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html
  class="no-js"
  lang="en"
><!--<![endif]-->
  <head>
    <meta charset="utf-8" />
    <title>Optimising the Minkowski distance, part 1: vector subtraction</title>
    <meta name="author" content="Jodie Burchell" />

    <meta name="HandheldFriendly" content="True" />
    <meta name="MobileOptimized" content="320" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="description" content="Optimising the Minkowski distance, part 1: vector subtraction written June 14, 2022 in python,machine learning">
  <meta name="keywords" content="numpy, python, minkowski distance, euclidean distance, manhattan distance" />

    <link
      rel="canonical"
      href="https://t-redactyl.github.io/blog/2022/06/optimising-the-minkowski-distance-part-1-vector-subtraction.html"
    />

    <link href="https://t-redactyl.github.io/favicon.png" rel="icon" />

    <link
      href="https://t-redactyl.github.io/feeds/all.atom.xml"
      type="application/atom+xml"
      rel="alternate"
      title="Standard error Full Atom Feed"
    />
      <link
      href="https://t-redactyl.github.io/theme/css/screen.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
    <link
      href="https://t-redactyl.github.io/theme/css/tomorrow.css"
      media="screen, projection"
      rel="stylesheet"
      type="text/css"
    />
     <script src="https://cdnjs.cloudflare.com/ajax/libs/modernizr/2.8.3/modernizr.js"></script>
    <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
    <!-- KaTeX for math rendering -->
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.css"
      integrity="sha384-VEnyslhHLHiYPca9KFkBB3CMeslnM9CzwjxsEbZTeA21JBm7tdLwKoZmCt3cZTYD"
      crossorigin="anonymous"
    />
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/katex.min.js"
      integrity="sha384-O4hpKqcplNCe+jLuBVEXC10Rn1QEqAmX98lKAIFBEDxZI0a+6Z2w2n8AEtQbR4CD"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0-beta1/contrib/auto-render.min.js"
      integrity="sha384-IiI65aU9ZYub2MY9zhtKd1H2ps7xxf+eb2YFG9lX6uRqpXCvBTOidPRCXCrQ++Uc"
      crossorigin="anonymous"
    ></script>
   </head>
  <body>
    <a href="/" class="home-icon">
      <img src="https://t-redactyl.github.io/theme/images/home.png" />
    </a>
<article role="article" class="full-single-article">
  <div class="container">
    <div class="row">
      <div class="col-md-8 col-md-offset-2">
        <h1>Optimising the Minkowski distance, part 1: vector subtraction</h1>
        <div class="meta">
          written <time datetime="2022-06-14T00:00:00+02:00">June 14, 2022</time>
          in <span class="categories">
            <a href="https://t-redactyl.github.io/tag/python.html">python</a>,            <a href="https://t-redactyl.github.io/tag/machine-learning.html">machine learning</a>          </span>
        </div>
        <p>In the <a href="https://t-redactyl.github.io/blog/2022/06/just-enough-linear-algebra-to-understand-the-minkowski-distance.html">last blog post</a>, we discussed how to calculate the Manhattan and Euclidean distances from first principles. However, in that post, we did a very manual implementation for a single pair of vectors, which would not generalise well to more than one pair and would become cumbersome for more than a few dimensions. As such, in this blog post we will discuss how to implement the Minkowski distance calculation for vectors of any number of dimensions and for any number of pairs. As doing pairwise calculations can become very computationally expensive, we will also be exploring how to optimise our distance calculations using some further knowledge from linear algebra in both this blog post and the coming&nbsp;two.</p>
<h2>Our inital&nbsp;attempt</h2>
<p>Let&#8217;s start by revisiting our manual implementation of the Euclidean&nbsp;distance:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">p</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">diff_1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span>
<span class="n">diff_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span>
<span class="n">diff_3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span>
<span class="n">diff_4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span>

<span class="n">euclidean_distance_sq</span> <span class="o">=</span> <span class="n">diff_1</span> <span class="o">+</span> <span class="n">diff_2</span> <span class="o">+</span> <span class="n">diff_3</span> <span class="o">+</span> <span class="n">diff_4</span>
<span class="n">euclidean_distance</span> <span class="o">=</span> <span class="n">euclidean_distance_sq</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
<span class="n">euclidean_distance</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">6.557438524302</span>
</code></pre></div>

<p>Right away, we can see one possibility for generalising our code over as many dimensions as we like: we can run all of our difference calculations in a loop. Let&#8217;s see how this&nbsp;looks:</p>
<div class="highlight"><pre><span></span><code><span class="n">diffs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
    <span class="n">diffs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">element</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">element</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span><span class="p">)</span>
</code></pre></div>

<p>We now have a list containing the squared absolute differences, which we can then&nbsp;add.</p>
<div class="highlight"><pre><span></span><code><span class="n">euclidean_distance_sq</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span>
</code></pre></div>

<p>Let&#8217;s bundle this up into our first Minkowski distance&nbsp;function.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">calculate_minkowski_distance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the Minkowski distance between two vectors, X and Y. When p = 1, calculates the Manhattan distance, when p = 2, calculates the Euclidean distance.&quot;&quot;&quot;</span>
    <span class="n">i</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">diffs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">element</span><span class="p">]</span> <span class="o">-</span> <span class="n">Y</span><span class="p">[</span><span class="n">element</span><span class="p">])</span> <span class="o">**</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">abs_diffs</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">abs_diffs</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
</code></pre></div>

<p>If we apply it to our two test vectors, we can see we get the exact same answer as when we calculated it&nbsp;step-by-step:</p>
<div class="highlight"><pre><span></span><code><span class="n">calculate_minkowski_distance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">6.557438524302</span>
</code></pre></div>

<p>We now need a way of applying our newly minted Minkowski distance function to multiple pairs at the same time. What we need to do is compare every vector all other vectors pairwise, and the simplest way of doing this is within a nested loop. We&#8217;ll create an additional vector, <span class="math">\(Z\)</span> to compare to <span class="math">\(X\)</span> and <span class="math">\(Y\)</span>. We then combine these three vectors into a list of&nbsp;lists.</p>
<div class="highlight"><pre><span></span><code><span class="n">Z</span> <span class="o">=</span> <span class="p">[</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">vectors</span> <span class="o">=</span> <span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">Z</span><span class="p">]</span>
</code></pre></div>

<p>What we&#8217;ll now do is loop over each vector in this list, comparing <span class="math">\(X\)</span> with itself, <span class="math">\(X\)</span> with <span class="math">\(Y\)</span>, <span class="math">\(X\)</span> with <span class="math">\(Z\)</span>, etc., using two nested for&nbsp;loops.</p>
<div class="highlight"><pre><span></span><code><span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">:</span>
    <span class="n">tmp_distances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">:</span>
        <span class="n">tmp_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calculate_minkowski_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_distances</span><span class="p">)</span>
</code></pre></div>

<p>Finally, we can output the pairwise distance matrix to a Pandas&nbsp;DataFrame.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
</code></pre></div>

<div>
<table class="table table-bordered">
  <thead>
    <tr style="text-align: right;">
      <th style="text-align:center"><b></b></th>
      <th style="text-align:center"><b>0</b></th>
      <th style="text-align:center"><b>1</b></th> 
      <th style="text-align:center"><b>2</b></th> 
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align:center">0</td>
      <td style="text-align:center">0.000000</td>
      <td style="text-align:center">6.557439</td>
      <td style="text-align:center">8.602325</td>
    </tr>
    <tr>
      <td style="text-align:center">1</td>
      <td style="text-align:center">6.557439</td>
      <td style="text-align:center">0.000000</td>
      <td style="text-align:center">7.937254</td>
    </tr>
    <tr>
      <td style="text-align:center">2</td>
      <td style="text-align:center">8.602325</td>
      <td style="text-align:center">7.937254</td>
      <td style="text-align:center">0.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>We can see that everything makes sense: vectors compared with themselves have a distance of 0, and that the distance we have already calculated between <span class="math">\(X\)</span> and <span class="math">\(Y\)</span> is still returned as 6.56. Let&#8217;s now package this up into a function and see how it performs when calculating pairwise differences on our beans&nbsp;dataset.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">apply_minkowski_distance</span><span class="p">(</span><span class="n">vectors</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">p</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">:</span>
        <span class="n">tmp_distances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">:</span>
            <span class="n">tmp_distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">calculate_minkowski_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
        <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tmp_distances</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
</code></pre></div>

<p>As a refresher for those of you who may not have read the last blog post, the <a href="https://archive.ics.uci.edu/ml/datasets/Dry+Bean+Dataset#">dry bean dataset</a> describes the characteristics of 13,611 images of dried beans across 7 different types. There are 16 features describing the beans, such as their area, aspect ratio and roundness. We&#8217;ll prepare three samples from this dataset for testing: a sample of 100 observations using only three of the features (<code>MajorAxisLength</code>, <code>MinorAxisLength</code> and <code>roundness</code>); all observations using only the above three features; and the entire dataset with all 16&nbsp;features.</p>
<p>For each of our tests, we&#8217;ll use the Euclidean distance (so, <span class="math">\(p = 2\)</span>).</p>
<p>As our function above takes in a list of lists containing each of the vectors, we convert our Pandas DataFrames to this format by first extracting the values of each row using <code>values</code> and then converting the values to a list using <code>tolist()</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">beans</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s2">&quot;data/Dry_Bean_Dataset.xlsx&quot;</span><span class="p">)</span>

<span class="n">list_sample_1</span> <span class="o">=</span> <span class="n">beans</span><span class="p">[[</span><span class="s2">&quot;MajorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;MinorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;roundness&quot;</span><span class="p">]][:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">list_sample_2</span> <span class="o">=</span> <span class="n">beans</span><span class="p">[[</span><span class="s2">&quot;MajorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;MinorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;roundness&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">list_sample_3</span> <span class="o">=</span> <span class="n">beans</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
</code></pre></div>

<p>We then run the pairwise Euclidean distance calculation over each of our&nbsp;samples.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_1</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">list_sample_1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 84.5 ms, sys: 34.2 ms, total: 119 ms</span>
<span class="err">Wall time: 89.4 ms</span>
</code></pre></div>

<p>Our small sample with three features finishes relatively&nbsp;quickly.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_2</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">list_sample_2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 16min 47s, sys: 18.2 s, total: 17min 5s</span>
<span class="err">Wall time: 16min 56s</span>
</code></pre></div>

<p>However, when we move up to just over 100 times that many observations, our operation takes more than 10,000 times as long to complete, clocking in at an eyewatering 17 minutes. It&#8217;s easy to see why when we look at the code: in our nested for loop we&#8217;re multiplying every single element by every other element (including itself), meaning that the number of operations we need to complete is the square of the number of vectors. You can confirm this by looking at our example using <span class="math">\(X\)</span>, <span class="math">\(Y\)</span> and <span class="math">\(Z\)</span>: we had three vectors, but ended up with 9 calculations in our distance&nbsp;matrix.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_3</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">list_sample_3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 1h 5min 48s, sys: 2min 15s, total: 1h 8min 4s</span>
<span class="err">Wall time: 1h 6min 37s</span>
</code></pre></div>

<p>When using all 16 features, we can see that our processing time has just increased approximately fourfold. This makes sense given that we&#8217;re looping over each element in the vector to get the difference scores. Since we&#8217;ve jumped from 3 to 16 features, we&#8217;d expect a corresponding increase in the processing time for each distance calculation. This calculation of the difference score element-by-element is the first inefficiency we&#8217;ll tackle. To understand how to do so, let&#8217;s have a discussion about some of the arithmetic we can do with&nbsp;vectors.</p>
<h2>Vector&nbsp;subtraction</h2>
<p>Just like with numbers, we can do some simple arithmetic operations with vectors. Relevant to our case, we can take two vectors with the same number of elements and subtract them. This results in the corresponding elements being lined up and the second subtracted from the first. Let&#8217;s see an&nbsp;example.</p>
<div class="highlight"><pre><span></span><code><span class="n">Xm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>
<span class="n">Ym</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>

<span class="n">Ym</span> <span class="o">-</span> <span class="n">Xm</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([-4, -1, -1, -5])</span>
</code></pre></div>

<p>We can see that by subtracting <span class="math">\(Xm\)</span> from <span class="math">\(Ym\)</span>, we ended up with pairwise subtraction of each element of each vector, with <span class="math">\(Ym_1 - Xm_1 = 1 - 5 = -4\)</span>, <span class="math">\(Ym_2 - Xm_2 = 6 - 7 = -1\)</span>, and so on. You can probably see already that if we can replace the for loop to calculate the difference in our Minkowski function with this vectorised solution, we could save quite a lot of processing&nbsp;time.</p>
<p>In order to fully replace this functionality, we need to know about two other things we can do with vectors. Using NumPy, we can apply an <a href="https://numpy.org/doc/stable/reference/generated/numpy.absolute.html">absolute difference function</a> to each element in the vector. In addition, we can raise each element in a vector to a power (also known as the Hadamard power) using NumPy&#8217;s <code>power</code> <a href="https://numpy.org/doc/stable/reference/generated/numpy.power.html">method</a>. Let&#8217;s see these both in&nbsp;action.</p>
<div class="highlight"><pre><span></span><code><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Ym</span> <span class="o">-</span> <span class="n">Xm</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([4, 1, 1, 5])</span>
</code></pre></div>

<p>You can see it has worked, with all values now converted to positive. Let&#8217;s now apply the <code>power</code> function:</p>
<div class="highlight"><pre><span></span><code><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">Ym</span> <span class="o">-</span> <span class="n">Xm</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">array([16,  1,  1, 25])</span>
</code></pre></div>

<p>We&#8217;ve now replicated all the functionality we were including in the loop in our Minkowski function. Let&#8217;s update it and see whether our performance has&nbsp;improved.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">calculate_minkowski_distance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Calculates the Minkowski distance between two vectors, X and Y. When p = 1, calculates the Manhattan distance, when p = 2, calculates the Euclidean distance.&quot;&quot;&quot;</span>
    <span class="n">diffs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">Y</span><span class="p">),</span> <span class="n">p</span><span class="p">)</span>
    <span class="n">abs_diffs</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">diffs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">abs_diffs</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">p</span><span class="p">)</span>
</code></pre></div>

<p>As a quick sanity check, let&#8217;s confirm that we get the same answer as with our previous implementation of the&nbsp;function.</p>
<div class="highlight"><pre><span></span><code><span class="n">calculate_minkowski_distance</span><span class="p">(</span><span class="n">Xm</span><span class="p">,</span> <span class="n">Ym</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">6.557438524302</span>
</code></pre></div>

<p>Having confirmed this, let&#8217;s test it out with the same samples as we used earlier. We now need to convert these into NumPy arrays to be able to exploit the vector functions we&#8217;ve used in our&nbsp;function.</p>
<div class="highlight"><pre><span></span><code><span class="n">array_sample_1</span> <span class="o">=</span> <span class="n">beans</span><span class="p">[[</span><span class="s2">&quot;MajorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;MinorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;roundness&quot;</span><span class="p">]][:</span><span class="mi">100</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array_sample_2</span> <span class="o">=</span> <span class="n">beans</span><span class="p">[[</span><span class="s2">&quot;MajorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;MinorAxisLength&quot;</span><span class="p">,</span> <span class="s2">&quot;roundness&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">array_sample_3</span> <span class="o">=</span> <span class="n">beans</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Class&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</code></pre></div>

<p>Let&#8217;s now test out how it performs compared to our last&nbsp;implementation.</p>
<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_1</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">array_sample_1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 52.5 ms, sys: 2.74 ms, total: 55.3 ms</span>
<span class="err">Wall time: 53.6 ms</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_2</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">array_sample_2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 13min 1s, sys: 6.9 s, total: 13min 8s</span>
<span class="err">Wall time: 13min 10s</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="o">%</span><span class="n">time</span> <span class="n">list_min_3</span> <span class="o">=</span> <span class="n">apply_minkowski_distance</span><span class="p">(</span><span class="n">array_sample_3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="err">CPU times: user 17min 16s, sys: 7.35 s, total: 17min 23s</span>
<span class="err">Wall time: 17min 26s</span>
</code></pre></div>

<p>Whoo hoo, we managed to knock our calculation using all 16 vectors down to around a quarter of the original time! It seems that eliminating the loop to calculate the difference between vector elements has definitely sped things up. However, ~15 minutes is still a long time, especially given that we&#8217;re only dealing with around 13,000 observations. This current implementation is still being slowed down by the nested for loop we&#8217;re using to apply the Minkowski distance formula to all pairs. Luckily, NumPy has another solution for us here called <a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">broadcasting</a>, which we will discuss in the next blog post in this&nbsp;series.</p>
        <hr class="divider-short"/>
        <!-- Disqus goes here -->
        <!-- <section>
          <h1>Comments</h1>
          <div id="disqus_thread" aria-live="polite">Disqus goes here</div>
        </section>
        -->
      </div>
    </div>
  </div>
</article>
    <footer id="footer" class="her-row">
      <div class="container">
        <div class="row">
          <div class="col-md-1">
            <a href="/"><h4>Home</h4></a>
          </div>

          <div class="col-md-2">
            <div class="social-icon-list">
              <a href="https://twitter.com/t_redactyl"
                ><img
                  src="https://t-redactyl.github.io/theme/images/glyphicons_social_31_twitter.png"
              /></a>
               <a href="https://github.com/t-redactyl"
                ><img
                  src="https://t-redactyl.github.io/theme/images/glyphicons_social_21_github.png"
              /></a>
              </div>
          </div>
          <div class="pull-right">
            <h4>
              Powered by <a href="http://blog.getpelican.com/">Pelican</a>.
              Designed by <a href="http://AdrianArtiles.com">Adrian Artiles</a>.
              Title picture by
              <a
                href="https://pixabay.com/en/brandenburg-gate-berlin-landmark-2010656/"
                >Couleur via Pixabay</a
              >.
            </h4>
          </div>
        </div>
      </div>
    </footer>

    <!-- KaTeX rendering -->
    <script>
      renderMathInElement(document.body);
    </script>

 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66946155-1', 'auto');
  ga('send', 'pageview');

</script>    </body>
</html>